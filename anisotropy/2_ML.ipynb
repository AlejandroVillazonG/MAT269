{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AdT43PYlExN"
      },
      "source": [
        "# MLE para anisotropía geométrica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riz484FWlExT"
      },
      "source": [
        "Recordemos los supuestos realizados,\n",
        "$$\\mathbf{y} = (y_1, \\ldots, y_n)^\\top \\sim \\text{N}(0,\\mathbf{\\Sigma}(\\mathbf{A}))$$\n",
        "\n",
        "$$\\mathbf{\\Sigma}(\\mathbf{A})_{i,j} = c(\\mathbf{s_i},\\mathbf{s_j},\\mathbf{A}) = C(\\mathbf{h}:=\\mathbf{s_i}-\\mathbf{s_j}, \\mathbf{A}) = \\mathcal{M}_{\\theta,\\nu = 3/2}\\left(\\sqrt{\\mathbf{h}^\\top \\mathbf{A} \\mathbf{h}}\\right)$$\n",
        "\n",
        "$$\\mathcal{M}(x)_{\\theta,\\nu = 3/2} = (1+x/\\theta) \\exp\\left( -x/\\theta \\right), \\qquad \\mathbf{A} = \\mathbf{P}(\\alpha)\\mathbf{D}(\\text{ratio})\\mathbf{P}^\\top(\\alpha)$$\n",
        "donde\n",
        "$$\\mathbf{P}(\\alpha) = \\begin{pmatrix}\\cos{\\alpha} & \\sin{\\alpha} \\\\ -\\sin{\\alpha} & \\cos{\\alpha}\\end{pmatrix}, \\qquad \\mathbf{D}(\\text{ratio}) = \\begin{pmatrix}1 & 0 \\\\ 0 &\\text{ratio}\\end{pmatrix},\\qquad \\alpha\\in[0,\\pi), \\theta>0, \\text{ratio}\\in(0,1]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkiKcfBKlExU"
      },
      "source": [
        "Luego, la función de log-verosimilitud para la matriz de parámetros $\\mathbf{A}$ y el campo espacial $\\mathbf{y}$ viene dada por:\n",
        "$$\\ell(\\mathbf{A}, \\mathbf{y}) = -\\frac{1}{2}\\left[\\mathbf{y}^\\top\\mathbf{\\Sigma^{-1}(\\mathbf{A})}\\mathbf{y} + \\log\\det\\left(\\mathbf{\\Sigma(\\mathbf{A})}\\right) + n\\log(2\\pi)\\right]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rINGmkdFlExV"
      },
      "source": [
        "Similar al paper, para que los resultados sean comparables se calculará el estimador máximo verosimil de los parámetros, evaluando en cada configuración creada del conjunto de entrenamiento utilizada para entrenar la red neuronal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWbDgOyulExV"
      },
      "source": [
        "Importamos las librerías necesarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7HeZJ3MZlExV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import cholesky as chol, cho_solve\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NADmzt7MlExX"
      },
      "source": [
        "Definimos algunas funciones auxiliares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V8HWbuC-lExX"
      },
      "outputs": [],
      "source": [
        "def generar_grilla(sqrt_n):\n",
        "    xx = np.linspace(1,sqrt_n,sqrt_n)\n",
        "    X, Y = np.meshgrid(xx,xx)\n",
        "    return np.column_stack((X.flatten(), Y.flatten())) #Ordenados de izq a der y de abajo hacia arriba\n",
        "\n",
        "P = lambda alpha: np.array([[np.cos(alpha), np.sin(alpha)],[-np.sin(alpha), np.cos(alpha)]])\n",
        "D = lambda ratio: np.diag([1,ratio])\n",
        "A = lambda alpha, ratio: P(alpha) @ D(ratio) @ P(alpha).T\n",
        "\n",
        "matern_model = lambda t, x: (1 + x/t) * np.exp(-x/t) # nu=3/2\n",
        "\n",
        "def cholesky(alpha, t, ratio, H):\n",
        "    sqrt_H_TAH = np.sqrt(np.einsum('ijk,ijk->ij', H @ A(alpha, ratio) , H))\n",
        "    sigma = matern_model(t, sqrt_H_TAH)\n",
        "    return chol(sigma, lower=True, overwrite_a=True) # np.linalg.cholesky(sigma)\n",
        "\n",
        "def ML(alpha, t, ratio, H, Z):\n",
        "    '''\n",
        "    Z debe ser un vector con el orden correcto dado por los puntos.\n",
        "    '''\n",
        "    L = cholesky(alpha, t, ratio, H)\n",
        "    log_det_cov = 2 * np.sum(np.log(np.diag(L)))\n",
        "    temp = cho_solve((L, True), Z)\n",
        "    return -0.5 * (log_det_cov + np.dot(Z, temp))\n",
        "\n",
        "def maximize(Z, y_train, H):\n",
        "    '''\n",
        "    Z debe ser un vector con el orden correcto dado por los puntos.\n",
        "    '''\n",
        "    max_value = -np.inf\n",
        "    for alpha, t, ratio in y_train:\n",
        "        if ML(alpha, t, ratio, H, Z) > max_value:\n",
        "            max_value = ML(alpha, t, ratio, H, Z)\n",
        "            MLE = (alpha, t, ratio)\n",
        "    return MLE\n",
        "\n",
        "def maximizar(Z, y_train, H): # Version paralelizada\n",
        "    results = Parallel(n_jobs=12)(delayed(ML)(alpha, theta, ratio, H, Z) for alpha, theta, ratio in y_train)\n",
        "    return y_train[results.index(max(results))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNkKH9cYlExX"
      },
      "source": [
        "Generamos el tensor de distancias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OP8_mvFHlExY"
      },
      "outputs": [],
      "source": [
        "sqrt_n = 16\n",
        "points = generar_grilla(sqrt_n)\n",
        "H = points[:, np.newaxis, :] - points[np.newaxis, :, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4-XwuCmlExY"
      },
      "source": [
        "Importamos el conjunto de entrenamiento y prueba generado en el primer script."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf7BX0TFlT60",
        "outputId": "29384d59-2221-4660-b572-1e90984be5bf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RtwjPXYslExY"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/10sem 2023-2/Ayud Inv/data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rodD5K0xlExZ"
      },
      "outputs": [],
      "source": [
        "X_test = np.load(path + 'X_test.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU6PuTeRlExa"
      },
      "source": [
        "# Calculamos MLE optimizando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "spLciS0nlExa"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "def negative_log_likelihood(params, H, Z):\n",
        "    alpha, t, ratio = params\n",
        "    return -ML(alpha, t, ratio, H, Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zcPLKIHClExb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc05cdd-ddbf-47e8-fed4-226d11f6c9d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54000, 16, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "initial_guess = [np.deg2rad((0+180)/2), (0.02+5)/2, (0+1)/2]\n",
        "tol = 1e-6\n",
        "bounds = [(0, np.pi-tol), (0.0+tol, np.inf), (0.0+tol, 1.0)]\n",
        "y_pred_ML_opt = []\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SzDQhcSFlExb",
        "outputId": "070512ad-e6e0-4bf9-8aa0-8d7471e23aed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4h 22min 39s, sys: 3h 8min 7s, total: 7h 30min 47s\n",
            "Wall time: 4h 32min 9s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for field in tqdm(X_test, desc='progress', ncols=100, leave=False):\n",
        "    Z = np.flipud(field).ravel()\n",
        "    y_pred_ML_opt.append(minimize(negative_log_likelihood, initial_guess, args=(H, Z), bounds=bounds, method='L-BFGS-B').x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Pmuu2DrYlExc"
      },
      "outputs": [],
      "source": [
        "np.save(path+'y_pred_ML_opt.npy', np.array(y_pred_ML_opt))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}